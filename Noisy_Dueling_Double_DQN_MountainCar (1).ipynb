{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Noisy_Dueling_Double_DQN_MountainCar.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TSExFYIi4U-R",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import gym\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import os\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GLGOeQZ74U-X",
        "colab": {}
      },
      "source": [
        "env = gym.make('MountainCar-v0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO_QoCxIev28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import multiply\n",
        "from tensorflow.keras.layers import InputSpec\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "\n",
        "# Layer Implementation: https://github.com/chucnorrisful/dqn/blob/master/noisyNetLayers.py\n",
        "\n",
        "class NoisyDense(Dense):\n",
        "    def __init__(self, units, **kwargs):\n",
        "        self.output_dim = units\n",
        "        super(NoisyDense, self).__init__(units, **kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 2\n",
        "        self.input_dim = input_shape[-1]\n",
        "\n",
        "        self.kernel = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      name='kernel',\n",
        "                                      regularizer=None,\n",
        "                                      constraint=None)\n",
        "\n",
        "        \n",
        "        self.kernel_sigma = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                      initializer=initializers.Constant(0.017),\n",
        "                                      name='sigma_kernel',\n",
        "                                      regularizer=None,\n",
        "                                      constraint=None)\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(shape=(self.units,),\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        name='bias',\n",
        "                                        regularizer=None,\n",
        "                                        constraint=None)\n",
        "\n",
        "            \n",
        "            self.bias_sigma = self.add_weight(shape=(self.units,),\n",
        "                                        initializer=initializers.Constant(0.017),\n",
        "                                        name='bias_sigma',\n",
        "                                        regularizer=None,\n",
        "                                        constraint=None)\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "        self.input_spec = InputSpec(min_ndim=2, axes={-1: self.input_dim})\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \n",
        "        self.kernel_epsilon = K.random_normal(shape=(self.input_dim, self.units))\n",
        "\n",
        "        w = self.kernel + (self.kernel_sigma * self.kernel_epsilon)\n",
        "        output = K.dot(inputs, w)\n",
        "\n",
        "        if self.use_bias:\n",
        "            \n",
        "            self.bias_epsilon = K.random_normal(shape=(self.units,))\n",
        "\n",
        "            b = self.bias + (self.bias_sigma * self.bias_epsilon)\n",
        "            output = output + b\n",
        "        if self.activation is not None:\n",
        "            output = self.activation(output)\n",
        "        return output\n",
        "    \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \n",
        "        return (input_shape[0], self.output_dim)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JFDEPyC94U-a",
        "colab": {}
      },
      "source": [
        "state_size= env.observation_space.shape[0]\n",
        "state_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7d7TuvNG4U-d",
        "colab": {}
      },
      "source": [
        "action_size= env.action_space.n\n",
        "action_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-xDHmlNC4U-g",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oa-sP1lh4U-k",
        "colab": {}
      },
      "source": [
        "n_episodes= 70000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ULJuSeKF4U-m",
        "colab": {}
      },
      "source": [
        "output_dir= 'model_output/MountainCar'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NneZmMaQ4U-p",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cizjkV1k4U-s",
        "colab": {}
      },
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self, state_size, action_size):\n",
        "        self.env= env\n",
        "        self.state_size= state_size\n",
        "        self.action_size= action_size\n",
        "        \n",
        "        self.memory= deque(maxlen=200000)\n",
        "        \n",
        "        self.gamma= 0.99\n",
        "        \n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_decay= .92\n",
        "        self.epsilon_min=0.00001\n",
        "        \n",
        "        self.learning_rate= 0.001251\n",
        "        self.model= self._build_model()\n",
        "        self.target_model=self._build_model()\n",
        "        \n",
        "        self.update_target_model()\n",
        "        \n",
        "    def _build_model(self):\n",
        "        state_shape= self.env.observation_space.shape\n",
        "        input_layer= tf.keras.Input(shape=(state_shape))\n",
        "        fc1= tf.keras.layers.Dense(24, activation='relu') (input_layer)\n",
        "\n",
        "        fc2= NoisyDense(48, activation='relu') (fc1) \n",
        "        \n",
        "        advantage =tf.keras.layers.Dense(self.action_size, activation='linear') (fc2)\n",
        "        avgadv= tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x, axis=1, keepdims=True))(advantage)\n",
        "        subadv= tf.keras.layers.Subtract() ([advantage, avgadv])\n",
        "        \n",
        "        value = tf.keras.layers.Dense(1, activation='linear') (fc2)\n",
        "        qvals = tf.keras.layers.Add() ([value, subadv])\n",
        "        \n",
        "        model = tf.keras.Model(inputs=input_layer, outputs= qvals)\n",
        "        \n",
        "        model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(lr=self.learning_rate))\n",
        "        \n",
        "        return model\n",
        "    def update_target_model(self):\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "    \n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "    def act(self, state):\n",
        "        act_values= self.model.predict(state)\n",
        "        return np.argmax(act_values[0])\n",
        "    def replay(self, batch_size):\n",
        "        minibatch = random.sample(self.memory, batch_size)\n",
        "        states=[]\n",
        "        targets=[]\n",
        "        \n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "            target=reward\n",
        "            if not done:\n",
        "                target = (reward + self.gamma * np.amax(self.target_model.predict(next_state)[0]))\n",
        "            target_f= self.model.predict(state)\n",
        "            target_f[0][action]= target\n",
        "            states.append(state[0])\n",
        "            targets.append(target_f[0])\n",
        "            \n",
        "        self.model.fit(np.array(states), np.array(targets), epochs=1, verbose=0)\n",
        "            \n",
        "        \n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)\n",
        "            \n",
        "    \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TURoYt0U4U-w",
        "colab": {}
      },
      "source": [
        "agent= DQNAgent(state_size, action_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DNrbYkJp4U-1",
        "colab": {}
      },
      "source": [
        "done = False\n",
        "counter=0 \n",
        "scores_memory= deque(maxlen=100)\n",
        "test_score= deque(maxlen=100)\n",
        "for e in range(n_episodes):\n",
        "    state=env.reset()\n",
        "\n",
        "    state= np.reshape(state, [1, state_size])\n",
        "    \n",
        "    for time in range(7000):\n",
        "        #if e % 50==0:\n",
        "            #env.render()\n",
        "        action= agent.act(state)\n",
        "        next_state, reward, done, halp =env.step(action)\n",
        "        \n",
        "        next_state = np.reshape(next_state, [1, state_size])\n",
        "\n",
        "        \n",
        "        agent.remember(state, action, reward, next_state, done)\n",
        "            \n",
        "        if len(agent.memory)>batch_size:\n",
        "            agent.replay(batch_size)\n",
        "\n",
        "        \n",
        "        state = next_state\n",
        "\n",
        "        if done:\n",
        "            if time == 199:\n",
        "                    time=time+1\n",
        "            scores_memory.append(time)\n",
        "            scores_avg= np.mean(scores_memory)*-1\n",
        "\n",
        "            \n",
        "            print('Episode: {}/{}, score: {}, state: {}, 100 episode score avg: {}'.format(e+1, n_episodes, time, state, scores_avg))\n",
        "\n",
        "            break\n",
        "        \n",
        "        \n",
        "    if e % 50==0:\n",
        "        agent.save(output_dir + 'weights_final' + '{:04d}'.format(e) + \".hdf5\")\n",
        "        \n",
        "    for ep in range(100):\n",
        "        state=env.reset()\n",
        "\n",
        "        state= np.reshape(state, [1, state_size])\n",
        "        for timee in range(7000):\n",
        "            action= agent.act(state)\n",
        "            next_state, reward, done, halp =env.step(action)\n",
        "        \n",
        "            next_state = np.reshape(next_state, [1, state_size])\n",
        "\n",
        "        \n",
        "            state = next_state\n",
        "\n",
        "            if done:\n",
        "                if timee == 199:\n",
        "                    timee=timee+1\n",
        "                test_score.append(timee)\n",
        "\n",
        "                break\n",
        "    \n",
        "    tscores_avg= np.mean(test_score)*-1\n",
        "    print('Test_Episodes: {}/{}, score: {}, state: {}, 100 episode score avg: {}'.format(ep+1, ep+1, timee, state, tscores_avg))\n",
        "    if tscores_avg >=-110:\n",
        "      agent.save(output_dir + 'weights_final' + '{:04d}'.format(e+1) + \".hdf5\")\n",
        "    agent.update_target_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8RLmNZ-G4U_d",
        "colab": {}
      },
      "source": [
        "#DQN and building around OpenAIgym reference:https://www.youtube.com/watch?v=OYhFoMySoVs\n",
        "#Double DQN reference: https://jaromiru.com/2016/11/07/lets-make-a-dqn-double-learning-and-prioritized-experience-replay/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAy_l5AteWlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
